#!/usr/bin/env python3
"""
è¨­å‚™é…ç½®æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ Whisper (GPU) å’Œ Gemma (CPU) çš„è¨­å‚™é…ç½®æ˜¯å¦æ­£ç¢º
"""

import torch
import logging
import sys
import os

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_gpu_availability():
    """æ¸¬è©¦ GPU å¯ç”¨æ€§"""
    logger.info("=== GPU å¯ç”¨æ€§æ¸¬è©¦ ===")
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        current_gpu = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_gpu)
        
        logger.info(f"âœ… CUDA å¯ç”¨")
        logger.info(f"GPU æ•¸é‡: {gpu_count}")
        logger.info(f"ç•¶å‰ GPU: {current_gpu}")
        logger.info(f"GPU åç¨±: {gpu_name}")
        logger.info(f"GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(current_gpu).total_memory / 1024**3:.1f} GB")
        return True
    else:
        logger.warning("âŒ CUDA ä¸å¯ç”¨ï¼Œæ‰€æœ‰æ¨¡å‹å°‡ä½¿ç”¨ CPU")
        return False

def test_whisper_device():
    """æ¸¬è©¦ Whisper è¨­å‚™é…ç½®"""
    logger.info("\n=== Whisper è¨­å‚™æ¸¬è©¦ ===")
    
    try:
        from src.config import WHISPER_DEVICE
        logger.info(f"é…ç½®ä¸­çš„ Whisper è¨­å‚™: {WHISPER_DEVICE}")
        
        # æ¸¬è©¦ Whisper åˆå§‹åŒ–
        from src.core.transcriber import Transcriber
        transcriber = Transcriber()
        
        # ä¸å¯¦éš›åˆå§‹åŒ–æ¨¡å‹ï¼Œåªæª¢æŸ¥è¨­å‚™é‚è¼¯
        if WHISPER_DEVICE == "cuda" and torch.cuda.is_available():
            expected_device = "cuda"
        else:
            expected_device = "cpu"
        
        logger.info(f"âœ… Whisper é æœŸä½¿ç”¨è¨­å‚™: {expected_device.upper()}")
        return expected_device
        
    except ImportError as e:
        logger.error(f"âŒ ç„¡æ³•å°å…¥ Whisper ç›¸é—œæ¨¡çµ„: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ Whisper è¨­å‚™æ¸¬è©¦å¤±æ•—: {e}")
        return None

def test_gemma_device():
    """æ¸¬è©¦ Gemma è¨­å‚™é…ç½®"""
    logger.info("\n=== Gemma è¨­å‚™æ¸¬è©¦ ===")
    
    try:
        from src.config import GEMMA_DEVICE, GEMMA_QUANTIZATION
        logger.info(f"é…ç½®ä¸­çš„ Gemma è¨­å‚™: {GEMMA_DEVICE}")
        logger.info(f"é…ç½®ä¸­çš„ Gemma é‡åŒ–: {GEMMA_QUANTIZATION}")
        
        # æ¸¬è©¦ Gemma ç¿»è­¯å™¨
        from src.core.translator import GemmaTranslator
        translator = GemmaTranslator()
        
        logger.info(f"âœ… Gemma é æœŸä½¿ç”¨è¨­å‚™: {GEMMA_DEVICE.upper()}")
        
        if GEMMA_DEVICE == "cpu":
            logger.info("âœ… CPU æ¨¡å¼ï¼šå°‡ä¸ä½¿ç”¨é‡åŒ–ï¼Œä½¿ç”¨å…¨ç²¾åº¦æ¨¡å‹")
        else:
            logger.info(f"âœ… GPU æ¨¡å¼ï¼šå°‡ä½¿ç”¨ {GEMMA_QUANTIZATION} é‡åŒ–")
        
        return GEMMA_DEVICE
        
    except ImportError as e:
        logger.error(f"âŒ ç„¡æ³•å°å…¥ Gemma ç›¸é—œæ¨¡çµ„: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ Gemma è¨­å‚™æ¸¬è©¦å¤±æ•—: {e}")
        return None

def test_memory_usage():
    """æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    logger.info("\n=== è¨˜æ†¶é«”ä½¿ç”¨æ¸¬è©¦ ===")
    
    # CPU è¨˜æ†¶é«”
    try:
        import psutil
        cpu_memory = psutil.virtual_memory()
        logger.info(f"CPU è¨˜æ†¶é«”ç¸½é‡: {cpu_memory.total / 1024**3:.1f} GB")
        logger.info(f"CPU è¨˜æ†¶é«”å¯ç”¨: {cpu_memory.available / 1024**3:.1f} GB")
        logger.info(f"CPU è¨˜æ†¶é«”ä½¿ç”¨ç‡: {cpu_memory.percent:.1f}%")
    except ImportError:
        logger.warning("ç„¡æ³•ç²å– CPU è¨˜æ†¶é«”è³‡è¨Š (éœ€è¦ psutil)")
    
    # GPU è¨˜æ†¶é«”
    if torch.cuda.is_available():
        gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        gpu_memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
        gpu_memory_cached = torch.cuda.memory_reserved(0) / 1024**3
        
        logger.info(f"GPU è¨˜æ†¶é«”ç¸½é‡: {gpu_memory_total:.1f} GB")
        logger.info(f"GPU è¨˜æ†¶é«”å·²åˆ†é…: {gpu_memory_allocated:.1f} GB")
        logger.info(f"GPU è¨˜æ†¶é«”å·²å¿«å–: {gpu_memory_cached:.1f} GB")

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹è¨­å‚™é…ç½®æ¸¬è©¦...\n")
    
    # æ¸¬è©¦ GPU å¯ç”¨æ€§
    gpu_available = test_gpu_availability()
    
    # æ¸¬è©¦ Whisper è¨­å‚™é…ç½®
    whisper_device = test_whisper_device()
    
    # æ¸¬è©¦ Gemma è¨­å‚™é…ç½®
    gemma_device = test_gemma_device()
    
    # æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨
    test_memory_usage()
    
    # ç¸½çµ
    logger.info("\n=== æ¸¬è©¦ç¸½çµ ===")
    
    if whisper_device == "cuda" and gemma_device == "cpu":
        logger.info("âœ… é…ç½®æ­£ç¢ºï¼šWhisper ä½¿ç”¨ GPUï¼ŒGemma ä½¿ç”¨ CPU")
        logger.info("âœ… é€™æ¨£çš„é…ç½®å¯ä»¥æœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ï¼Œé¿å…è¨˜æ†¶é«”è¡çª")
    elif whisper_device == "cpu" and gemma_device == "cpu":
        logger.info("âš ï¸  å…©å€‹æ¨¡å‹éƒ½ä½¿ç”¨ CPUï¼ˆå¯èƒ½å› ç‚ºæ²’æœ‰ GPU æˆ– GPU ä¸å¯ç”¨ï¼‰")
    elif whisper_device == "cuda" and gemma_device == "cuda":
        logger.info("âš ï¸  å…©å€‹æ¨¡å‹éƒ½ä½¿ç”¨ GPUï¼ˆå¯èƒ½æœƒæœ‰è¨˜æ†¶é«”ä¸è¶³å•é¡Œï¼‰")
    else:
        logger.warning("â“ æœªé æœŸçš„è¨­å‚™é…ç½®çµ„åˆ")
    
    logger.info("\nğŸ¯ æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main() 