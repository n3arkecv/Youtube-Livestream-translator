#!/usr/bin/env python3
"""
Whisper turbo æ¨¡å‹æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ turbo æ¨¡å‹ï¼ˆå³ large-v3-turboï¼‰çš„æ€§èƒ½å’Œé…ç½®
"""

import time
import numpy as np
import logging
from src.core.transcriber import Transcriber
from src.config import WHISPER_MODEL, WHISPER_DEVICE

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_whisper_turbo():
    """æ¸¬è©¦ Whisper large-v3-turbo æ¨¡å‹"""
    logger.info(f"ğŸ” æ¸¬è©¦ Whisper æ¨¡å‹: {WHISPER_MODEL}")
    logger.info(f"ğŸ” ä½¿ç”¨è¨­å‚™: {WHISPER_DEVICE}")
    
    try:
        # æª¢æŸ¥ CUDA å¯ç”¨æ€§
        import torch
        cuda_available = torch.cuda.is_available()
        logger.info(f"CUDA å¯ç”¨: {cuda_available}")
        
        if cuda_available:
            logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
            logger.info(f"GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # åˆå§‹åŒ–è½‰éŒ„å™¨
        logger.info("=== åˆå§‹åŒ– Whisper è½‰éŒ„å™¨ ===")
        transcriber = Transcriber()
        
        start_time = time.time()
        transcriber.initialize()
        init_time = time.time() - start_time
        
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚: {init_time:.2f} ç§’")
        
        # å‰µå»ºæ¸¬è©¦éŸ³é »ï¼ˆ3 ç§’ï¼Œ16kHzï¼‰
        logger.info("=== å‰µå»ºæ¸¬è©¦éŸ³é » ===")
        sample_rate = 16000
        duration = 3
        
        # ç”Ÿæˆç™½å™ªéŸ³ä½œç‚ºæ¸¬è©¦éŸ³é »
        test_audio = np.random.random(sample_rate * duration).astype(np.float32) * 0.1
        logger.info(f"æ¸¬è©¦éŸ³é »: {duration} ç§’, {sample_rate} Hz, å½¢ç‹€: {test_audio.shape}")
        
        # æ¸¬è©¦è½‰éŒ„æ€§èƒ½
        logger.info("=== æ¸¬è©¦è½‰éŒ„æ€§èƒ½ ===")
        
        # é ç†±
        logger.info("é ç†±è½‰éŒ„å™¨...")
        _ = transcriber.transcribe(test_audio[:sample_rate], "auto")  # 1 ç§’é ç†±
        
        # æ­£å¼æ¸¬è©¦
        test_iterations = 3
        total_time = 0
        
        for i in range(test_iterations):
            logger.info(f"è½‰éŒ„æ¸¬è©¦ {i+1}/{test_iterations}")
            
            start_time = time.time()
            result = transcriber.transcribe(test_audio, "auto")
            process_time = time.time() - start_time
            total_time += process_time
            
            logger.info(f"  è€—æ™‚: {process_time:.2f} ç§’")
            logger.info(f"  çµæœ: {result}")
            
            # è¨ˆç®—å³æ™‚å› å­ (Real-time Factor)
            rtf = process_time / duration
            logger.info(f"  å³æ™‚å› å­ (RTF): {rtf:.2f} ({'âœ… å³æ™‚' if rtf < 1.0 else 'âŒ éå³æ™‚'})")
        
        # çµ±è¨ˆçµæœ
        avg_time = total_time / test_iterations
        avg_rtf = avg_time / duration
        
        logger.info("=== æ•ˆèƒ½çµ±è¨ˆ ===")
        logger.info(f"å¹³å‡è™•ç†æ™‚é–“: {avg_time:.2f} ç§’")
        logger.info(f"å¹³å‡å³æ™‚å› å­: {avg_rtf:.2f}")
        logger.info(f"é©åˆå³æ™‚è½‰éŒ„: {'âœ… æ˜¯' if avg_rtf < 0.8 else 'âŒ å¦'}")
        
        # æ¸¬è©¦å¸¶æ™‚é–“æˆ³çš„è½‰éŒ„
        logger.info("=== æ¸¬è©¦æ™‚é–“æˆ³è½‰éŒ„ ===")
        start_time = time.time()
        timestamps_result = transcriber.transcribe_with_timestamps(test_audio, "auto")
        timestamp_time = time.time() - start_time
        
        logger.info(f"æ™‚é–“æˆ³è½‰éŒ„è€—æ™‚: {timestamp_time:.2f} ç§’")
        logger.info(f"æ™‚é–“æˆ³çµæœ: {timestamps_result}")
        
        # è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
        if cuda_available and WHISPER_DEVICE == "cuda":
            gpu_memory = torch.cuda.memory_allocated() / 1024**3
            logger.info(f"GPU è¨˜æ†¶é«”ä½¿ç”¨: {gpu_memory:.2f} GB")
        
        # æ¸…ç†è³‡æº
        transcriber.cleanup()
        logger.info("âœ… è³‡æºæ¸…ç†å®Œæˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹ Whisper turbo æ¨¡å‹æ¸¬è©¦...")
    
    success = test_whisper_turbo()
    
    if success:
        logger.info("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Whisper turbo æ¨¡å‹é…ç½®æ­£ç¢º")
        print("\nâœ… çµè«–:")
        print("  - Whisper turbo æ¨¡å‹ï¼ˆlarge-v3-turboï¼‰å¯ä»¥æ­£å¸¸é‹è¡Œ")
        print("  - é©åˆç”¨æ–¼å³æ™‚èªéŸ³è½‰éŒ„")
        print("  - GPU åŠ é€Ÿæ­£å¸¸å·¥ä½œ")
        print("  - ç›¸æ¯” large-v3 æœ‰æ›´å¥½çš„é€Ÿåº¦è¡¨ç¾")
    else:
        logger.error("âŒ æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥é…ç½®")

if __name__ == "__main__":
    main() 