# 設備配置說明 - RTX 4070 最佳化

## 🎯 當前配置（已最佳化）

### GPU 使用（RTX 4070 - 8GB VRAM）
- **Whisper 語音識別** → CUDA 加速
- **模型**: turbo (最適合即時處理)
- **預期效能**: 比 CPU 快 5-10 倍

### CPU 使用（40GB RAM）
- **Gemma 3n 翻譯** → 全精度運行
- **模型**: google/gemma-3n-E2B-it
- **量化**: 無（CPU 模式下使用全精度）

## ✅ 配置檔案

### `src/config.py`
```python
# Whisper 設定
WHISPER_MODEL = "turbo"
WHISPER_DEVICE = "cuda"        # 使用 GPU

# Gemma 設定  
GEMMA_MODEL_NAME = "google/gemma-3n-E2B-it"
GEMMA_DEVICE = "cpu"           # 使用 CPU
GEMMA_QUANTIZATION = "int4"    # CPU 模式下會自動忽略
```

## 🔧 依賴版本

### PyTorch (CUDA 支援)
```
torch==2.5.1+cu121
torchaudio==2.5.1+cu121
```

### AI 模型支援
```
transformers>=4.53.0
accelerate>=0.26.0
whisper>=1.1.10
```

## 📊 預期效能

### Whisper (GPU)
- **延遲**: < 1 秒
- **準確度**: 95%+
- **GPU 記憶體**: 約 2-3GB

### Gemma (CPU)  
- **延遲**: 1-2 秒
- **翻譯品質**: 極高
- **RAM 使用**: 約 4-6GB

## 🚀 測試命令

### 檢查設備狀態
```bash
python test_device_setup.py
```

### 啟動應用程式
```bash
python -m src.gui.main_window
```

## 💡 故障排除

### CUDA 不可用
1. 檢查 NVIDIA 驅動程式: `nvidia-smi`
2. 重新安裝 CUDA PyTorch:
   ```bash
   pip uninstall torch torchaudio -y
   pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

### 記憶體不足
- **GPU 記憶體不足**: 減少 batch size 或使用較小的 Whisper 模型
- **CPU 記憶體不足**: 啟用 Gemma 量化或使用較小模型

---
*最後更新: 2025-07-10*
*適用於: RTX 4070 + 40GB RAM* 